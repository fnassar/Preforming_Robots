Katie Winkle
Before talking about how robots are to fit in our community as individuals, and what kind of rights they should have, we first need to talk about how we expect these robots to react, speak, and interact, about their security, and the kind of ethics they should have. People today are getting very dependent on AI, what if those robots were faces, talking responding being nice, mean, and aggressive what would we do? Katie Wrinkle works on human-robot interaction for socially assistive robots. Her approach to robot ethics mostly revolves around how robots can exist, interact, and communicate with different groups of people in an ethical and trustworthy way.

One of her research areas I found particularly interesting is Boosting Robot Credibility and Challenging Gender Norms: A Case for Feminist Robots - alt.HRI 2021[2] where she runs a test on the robot interaction from a feminist robot perspective and gets their reactions before and after talking to the robot to gauge how differently users would react to each of the modes. She found from those interactions, that when the robot used an argumentative approach to respond to the arguments regarding females working in the robotic field, they seemed to agree less with the feminist presentation of females in computer science than the users which the robots responded to aggressively. The latter group tended to support females in the field more than they previously did. It was not the same for females who appreciated the robot in the argumentative condition more and even gained more interest in understanding more about the robot’s mechanics after it than the controlled and aggressive robots.


This made me question how the controlled interactions robots maintain might not be the only way for robots to be effectively integrated into society. It shows that robots that could look like human representatives could maybe be more effective if they respond more like humans than the controlled calm robots. It also opens room to question a robot who exists if they should speak more in a controlled manner or less controlled and more natural manner but with limits in speech figures, or just have any way of speaking ignoring the limits. It is also interesting that the genders male and female, seem to respond differently to this test with females appreciating the argumentative and males having more change in opinion or interest with the aggressive robot.

One other research of hers that I found interesting is  Feminist Human-Robot Interaction: Disentangling Power, Principles and Practice for Beter, More Ethical HRI[1]. When she talks about power in this paper, she explains power as the idea that systems would empower certain groups of people because it was created by them, not by an equal distribution of power. This makes the system favor that certain group because that group was the one where data and systems were generated. The goal of this paper was to identify points that are lacking in HRI(Human-Robot Interaction) about feminist robots as a guide to help improve testing points for HRI. They also work to get HRI researchers to target more areas than just task performance and consider things like bodily experience and other targets that would improve the user experience and give the user more of a personal interaction with the robot than just a task-fulfilling machine. 

This paper raises many questions about the requirements of these tasks in our day-to-day society. Do we need to have robots interacting with humans to leave emotional impacts? This seems like it would lead humans to feel hurt, care for the HRIs, and maybe even miss their loss when they are not around. Referencing the first paper I mentioned, it seems like that would show positive effects on many people, even though it still seems to be unsure how this interaction would best be carried out or regulated. The second paper brings into perspective many important aspects of how one should test for the variables or conditions for which these robots interact and face different genders without offending them. One would say maybe it is best to try and interact with different genders differently if they do not react equally to everything the robot says. However, that could also be qualified as unequal or preferring one gender over the other and maybe it would still not be okay.

Talking about the ethics HRIs or just AI robots should have is a never-ending conversation of what they should and shouldn’t do. However, Winkle raises important issues regarding how robots interact with different groups of people. It is important to take notice of the fact that not everyone exists within the same environment and that if a robot were to exist in a place where different people exist, it needs to be trained to interact with each type of human it is meant to interact with. It is important to take into consideration how if the robot reflects the creator's likes and dislikes it's not enough. It should be essential to pass the robot through different testing levels that add more to its general value and morals to make it more suitable for everyone who could possibly interact with it.





[link 1](https://dl.acm.org/doi/pdf/10.1145/3568162.3576973)
[link 2](https://www.youtube.com/watch?v=58KxkBUg_bI)
